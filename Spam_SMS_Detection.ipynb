{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGFZDU0XIJeYJGP1ZF5l4r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakshik0524/Encryptix_task4/blob/main/Spam_SMS_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "ELdYDL0FBqfK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "O6mjN3INrJS8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c2a2bbc-e121-479c-d19c-a13eed570c5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.52.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy scikit-learn seaborn matplotlib joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.ensemble import VotingClassifier"
      ],
      "metadata": {
        "id": "BvC9f0c30EbT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VihhrwtK0Ku7",
        "outputId": "3f4e8373-68ee-4106-b098-bad714869ee0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the dataset in Google Drive\n",
        "data_path = '/content/drive/My Drive/spam.csv'\n",
        "\n",
        "# Load the dataset with a different encoding\n",
        "data = pd.read_csv(data_path, encoding='latin1')\n",
        "\n",
        "# Inspect the first few rows of the dataset\n",
        "print(data.head())\n",
        "\n",
        "# Check the structure of the dataset\n",
        "print(data.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-Ql-vjW0y3u",
        "outputId": "f8a911e9-6eb1-4e8f-bea9-cad56dd0a033"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     v1                                                 v2 Unnamed: 2  \\\n",
            "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
            "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
            "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
            "\n",
            "  Unnamed: 3 Unnamed: 4  \n",
            "0        NaN        NaN  \n",
            "1        NaN        NaN  \n",
            "2        NaN        NaN  \n",
            "3        NaN        NaN  \n",
            "4        NaN        NaN  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   v1          5572 non-null   object\n",
            " 1   v2          5572 non-null   object\n",
            " 2   Unnamed: 2  50 non-null     object\n",
            " 3   Unnamed: 3  12 non-null     object\n",
            " 4   Unnamed: 4  6 non-null      object\n",
            "dtypes: object(5)\n",
            "memory usage: 217.8+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Value Mapping"
      ],
      "metadata": {
        "id": "8kd14ZpEDPl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[['v1', 'v2']]\n",
        "data.columns = ['label', 'message']\n",
        "\n",
        "# Map labels to binary values\n",
        "data['label'] = data['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Check for any missing values\n",
        "print(data.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEEf0x2R1iOf",
        "outputId": "9542e5a7-a13c-4c73-de12-e2c131a76530"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label      0\n",
            "message    0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-e6522f95e9f9>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['label'] = data['label'].map({'ham': 0, 'spam': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Training"
      ],
      "metadata": {
        "id": "M5DR5o-BDaaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['message'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n"
      ],
      "metadata": {
        "id": "Mo49Ht2Q1kxd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes, Logistic Regression and Support Vector Machines to identify the spam messages"
      ],
      "metadata": {
        "id": "v646s-KyDdwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize classifiers\n",
        "nb_classifier = MultinomialNB()\n",
        "lr_classifier = LogisticRegression(max_iter=1000)\n",
        "svm_classifier = SVC(kernel='linear')\n",
        "\n",
        "# Train Naive Bayes classifier\n",
        "nb_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Train Logistic Regression classifier\n",
        "lr_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Train SVM classifier\n",
        "svm_classifier.fit(X_train_tfidf, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "S0SSlxU91pww",
        "outputId": "42e8574d-5df7-419b-d5a9-1c9a7ebf7da3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions using all three classifiers"
      ],
      "metadata": {
        "id": "pHe4gjSJDqJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with each classifier\n",
        "nb_predictions = nb_classifier.predict(X_test_tfidf)\n",
        "lr_predictions = lr_classifier.predict(X_test_tfidf)\n",
        "svm_predictions = svm_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Define a function to evaluate the models\n",
        "def evaluate_model(predictions, y_test):\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    precision = precision_score(y_test, predictions)\n",
        "    recall = recall_score(y_test, predictions)\n",
        "    f1 = f1_score(y_test, predictions)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Evaluate Naive Bayes classifier\n",
        "nb_results = evaluate_model(nb_predictions, y_test)\n",
        "print(f'Naive Bayes - Accuracy: {nb_results[0]}, Precision: {nb_results[1]}, Recall: {nb_results[2]}, F1-Score: {nb_results[3]}')\n",
        "\n",
        "# Evaluate Logistic Regression classifier\n",
        "lr_results = evaluate_model(lr_predictions, y_test)\n",
        "print(f'Logistic Regression - Accuracy: {lr_results[0]}, Precision: {lr_results[1]}, Recall: {lr_results[2]}, F1-Score: {lr_results[3]}')\n",
        "\n",
        "# Evaluate SVM classifier\n",
        "svm_results = evaluate_model(svm_predictions, y_test)\n",
        "print(f'SVM - Accuracy: {svm_results[0]}, Precision: {svm_results[1]}, Recall: {svm_results[2]}, F1-Score: {svm_results[3]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw0s2iZ61sru",
        "outputId": "36904782-54fd-4c55-bfcc-bf35f04aeef9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes - Accuracy: 0.9668161434977578, Precision: 1.0, Recall: 0.7533333333333333, F1-Score: 0.8593155893536121\n",
            "Logistic Regression - Accuracy: 0.9524663677130045, Precision: 0.970873786407767, Recall: 0.6666666666666666, F1-Score: 0.7905138339920948\n",
            "SVM - Accuracy: 0.979372197309417, Precision: 0.9703703703703703, Recall: 0.8733333333333333, F1-Score: 0.9192982456140351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter tuning for Logistic Regression"
      ],
      "metadata": {
        "id": "Xw9y-xinDzp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform hyperparameter tuning for Logistic Regression\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best parameters for Logistic Regression:\", best_params)\n",
        "\n",
        "# Create an ensemble of classifiers\n",
        "voting_clf = VotingClassifier(estimators=[\n",
        "    ('nb', nb_classifier),\n",
        "    ('lr', LogisticRegression(max_iter=1000, C=best_params['C'], solver=best_params['solver'])),\n",
        "    ('svm', SVC(kernel='linear', probability=True))\n",
        "], voting='soft')\n",
        "\n",
        "# Train the ensemble classifier\n",
        "voting_clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions with the ensemble classifier\n",
        "ensemble_predictions = voting_clf.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the ensemble classifier\n",
        "ensemble_results = evaluate_model(ensemble_predictions, y_test)\n",
        "print(f'Ensemble - Accuracy: {ensemble_results[0]}, Precision: {ensemble_results[1]}, Recall: {ensemble_results[2]}, F1-Score: {ensemble_results[3]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZN4qtM58dsf",
        "outputId": "773b0631-8c28-4369-a4cf-14d57810a71b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for Logistic Regression: {'C': 100, 'solver': 'liblinear'}\n",
            "Ensemble - Accuracy: 0.9811659192825112, Precision: 0.9708029197080292, Recall: 0.8866666666666667, F1-Score: 0.926829268292683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Support vector machines classifier prevails! (final answer)"
      ],
      "metadata": {
        "id": "tNZu3CY0D7Z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create example messages for prediction\n",
        "example_messages = [\n",
        "    \"Congratulations! You've won a $1,000 Walmart gift card. Go to http://bit.ly/12345 to claim now.\",\n",
        "    \"Hey, are we still meeting for lunch tomorrow?\",\n",
        "    \"URGENT! Your account has been compromised. Click the link to secure it.\",\n",
        "    \"Don't forget to bring your assignment to class.\",\n",
        "    \"Get 50% off your next purchase at our store. Limited time offer.\"\n",
        "]\n",
        "\n",
        "# Transform the example messages using the TF-IDF vectorizer\n",
        "example_messages_tfidf = tfidf_vectorizer.transform(example_messages)\n",
        "\n",
        "# Make predictions using each classifier\n",
        "nb_predictions = nb_classifier.predict(example_messages_tfidf)\n",
        "lr_predictions = lr_classifier.predict(example_messages_tfidf)\n",
        "svm_predictions = svm_classifier.predict(example_messages_tfidf)\n",
        "ensemble_predictions = voting_clf.predict(example_messages_tfidf)\n",
        "\n",
        "# Define a function to map the label to a string for readability\n",
        "def map_label_to_string(label):\n",
        "    return 'spam' if label == 1 else 'ham'\n",
        "\n",
        "# Display the results for the example messages\n",
        "print(\"Example Messages Classification:\\n\")\n",
        "for i, message in enumerate(example_messages):\n",
        "    print(f\"Message: {message}\")\n",
        "    print(f\"Naive Bayes Prediction: {map_label_to_string(nb_predictions[i])}\")\n",
        "    print(f\"Logistic Regression Prediction: {map_label_to_string(lr_predictions[i])}\")\n",
        "    print(f\"SVM Prediction: {map_label_to_string(svm_predictions[i])}\")\n",
        "    print(f\"Ensemble Prediction: {map_label_to_string(ensemble_predictions[i])}\")\n",
        "    print(\"-\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4y8PUo566Mm",
        "outputId": "1ad28dc3-bc4e-40fe-a2b4-f224631d8221"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example Messages Classification:\n",
            "\n",
            "Message: Congratulations! You've won a $1,000 Walmart gift card. Go to http://bit.ly/12345 to claim now.\n",
            "Naive Bayes Prediction: spam\n",
            "Logistic Regression Prediction: spam\n",
            "SVM Prediction: spam\n",
            "Ensemble Prediction: spam\n",
            "------------------------------------------------------------\n",
            "Message: Hey, are we still meeting for lunch tomorrow?\n",
            "Naive Bayes Prediction: ham\n",
            "Logistic Regression Prediction: ham\n",
            "SVM Prediction: ham\n",
            "Ensemble Prediction: ham\n",
            "------------------------------------------------------------\n",
            "Message: URGENT! Your account has been compromised. Click the link to secure it.\n",
            "Naive Bayes Prediction: ham\n",
            "Logistic Regression Prediction: ham\n",
            "SVM Prediction: spam\n",
            "Ensemble Prediction: spam\n",
            "------------------------------------------------------------\n",
            "Message: Don't forget to bring your assignment to class.\n",
            "Naive Bayes Prediction: ham\n",
            "Logistic Regression Prediction: ham\n",
            "SVM Prediction: ham\n",
            "Ensemble Prediction: ham\n",
            "------------------------------------------------------------\n",
            "Message: Get 50% off your next purchase at our store. Limited time offer.\n",
            "Naive Bayes Prediction: ham\n",
            "Logistic Regression Prediction: ham\n",
            "SVM Prediction: spam\n",
            "Ensemble Prediction: spam\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Top 10 features influencing LRC"
      ],
      "metadata": {
        "id": "9c86GkXvEJK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get the feature names from the TF-IDF vectorizer\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Get the coefficients of the logistic regression model\n",
        "coef = lr_classifier.coef_.flatten()\n",
        "\n",
        "# Create a DataFrame for the coefficients and feature names\n",
        "coef_df = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'coefficient': coef\n",
        "})\n",
        "\n",
        "# Sort by absolute value of coefficient\n",
        "coef_df['abs_coefficient'] = np.abs(coef_df['coefficient'])\n",
        "coef_df = coef_df.sort_values(by='abs_coefficient', ascending=False)\n",
        "\n",
        "# Display the top features\n",
        "print(\"Top 10 features influencing Logistic Regression predictions:\")\n",
        "print(coef_df.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp0u0yD47WQ8",
        "outputId": "cfaa2612-a88f-4b50-e8a1-6a92b9cdd357"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 features influencing Logistic Regression predictions:\n",
            "      feature  coefficient  abs_coefficient\n",
            "6838      txt     4.476817         4.476817\n",
            "4392   mobile     3.797081         3.797081\n",
            "1775    claim     3.711373         3.711373\n",
            "2910     free     3.607369         3.607369\n",
            "7353      www     3.454592         3.454592\n",
            "6269     stop     3.353968         3.353968\n",
            "6863       uk     3.245007         3.245007\n",
            "5520    reply     3.069216         3.069216\n",
            "529        50     2.986194         2.986194\n",
            "5821  service     2.951205         2.951205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attempts to enhance NBC, LRC"
      ],
      "metadata": {
        "id": "vYvIOqotESmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to the dataset in Google Drive\n",
        "data_path = '/content/drive/My Drive/spam.csv'\n",
        "\n",
        "# Load the dataset with a different encoding to handle potential encoding issues\n",
        "data = pd.read_csv(data_path, encoding='latin1')\n",
        "\n",
        "# Inspect the first few rows of the dataset\n",
        "print(data.head())\n",
        "\n",
        "# Check the structure of the dataset\n",
        "print(data.info())\n",
        "\n",
        "# Drop unnecessary columns and rename columns for convenience\n",
        "data = data[['v1', 'v2']]\n",
        "data.columns = ['label', 'message']\n",
        "\n",
        "# Map labels to binary values (ham: 0, spam: 1)\n",
        "data['label'] = data['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Check for any missing values\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['message'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Initialize classifiers\n",
        "nb_classifier = MultinomialNB()\n",
        "lr_classifier = LogisticRegression(max_iter=1000)\n",
        "svm_classifier = SVC(kernel='linear', probability=True)\n",
        "\n",
        "# Train Naive Bayes classifier\n",
        "nb_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Train Logistic Regression classifier\n",
        "lr_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Train SVM classifier\n",
        "svm_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions with each classifier\n",
        "nb_predictions = nb_classifier.predict(X_test_tfidf)\n",
        "lr_predictions = lr_classifier.predict(X_test_tfidf)\n",
        "svm_predictions = svm_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Define a function to evaluate the models\n",
        "def evaluate_model(predictions, y_test):\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    precision = precision_score(y_test, predictions)\n",
        "    recall = recall_score(y_test, predictions)\n",
        "    f1 = f1_score(y_test, predictions)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Evaluate Naive Bayes classifier\n",
        "nb_results = evaluate_model(nb_predictions, y_test)\n",
        "print(f'Naive Bayes - Accuracy: {nb_results[0]}, Precision: {nb_results[1]}, Recall: {nb_results[2]}, F1-Score: {nb_results[3]}')\n",
        "\n",
        "# Evaluate Logistic Regression classifier\n",
        "lr_results = evaluate_model(lr_predictions, y_test)\n",
        "print(f'Logistic Regression - Accuracy: {lr_results[0]}, Precision: {lr_results[1]}, Recall: {lr_results[2]}, F1-Score: {lr_results[3]}')\n",
        "\n",
        "# Evaluate SVM classifier\n",
        "svm_results = evaluate_model(svm_predictions, y_test)\n",
        "print(f'SVM - Accuracy: {svm_results[0]}, Precision: {svm_results[1]}, Recall: {svm_results[2]}, F1-Score: {svm_results[3]}')\n",
        "\n",
        "# Perform hyperparameter tuning for Logistic Regression\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],  # Different regularization strengths\n",
        "    'solver': ['liblinear', 'saga']  # Different solvers\n",
        "}\n",
        "\n",
        "# Use GridSearchCV to find the best parameters\n",
        "grid_search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Get the best parameters from GridSearchCV\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best parameters for Logistic Regression:\", best_params)\n",
        "\n",
        "# Create an ensemble of classifiers with soft voting\n",
        "voting_clf = VotingClassifier(estimators=[\n",
        "    ('nb', nb_classifier),\n",
        "    ('lr', LogisticRegression(max_iter=1000, C=best_params['C'], solver=best_params['solver'])),\n",
        "    ('svm', SVC(kernel='linear', probability=True))\n",
        "], voting='soft')\n",
        "\n",
        "# Train the ensemble classifier\n",
        "voting_clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions with the ensemble classifier\n",
        "ensemble_predictions = voting_clf.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the ensemble classifier\n",
        "ensemble_results = evaluate_model(ensemble_predictions, y_test)\n",
        "print(f'Ensemble - Accuracy: {ensemble_results[0]}, Precision: {ensemble_results[1]}, Recall: {ensemble_results[2]}, F1-Score: {ensemble_results[3]}')\n",
        "\n",
        "# Create example messages for prediction\n",
        "example_messages = [\n",
        "    \"Congratulations! You've won a $1,000 Walmart gift card. Go to http://bit.ly/12345 to claim now.\",\n",
        "    \"Hey, are we still meeting for lunch tomorrow?\",\n",
        "    \"URGENT! Your account has been compromised. Click the link to secure it.\",\n",
        "    \"Don't forget to bring your assignment to class.\",\n",
        "    \"Get 50% off your next purchase at our store. Limited time offer.\"\n",
        "]\n",
        "\n",
        "# Transform the example messages using the TF-IDF vectorizer\n",
        "example_messages_tfidf = tfidf_vectorizer.transform(example_messages)\n",
        "\n",
        "# Make predictions using each classifier\n",
        "nb_predictions = nb_classifier.predict(example_messages_tfidf)\n",
        "lr_predictions = lr_classifier.predict(example_messages_tfidf)\n",
        "svm_predictions = svm_classifier.predict(example_messages_tfidf)\n",
        "ensemble_predictions = voting_clf.predict(example_messages_tfidf)\n",
        "\n",
        "# Define a function to map the label to a string for readability\n",
        "def map_label_to_string(label):\n",
        "    return 'spam' if label == 1 else 'ham'\n",
        "\n",
        "# Display the results for the example messages\n",
        "print(\"Example Messages Classification:\\n\")\n",
        "for i, message in enumerate(example_messages):\n",
        "    print(f\"Message: {message}\")\n",
        "    print(f\"Naive Bayes Prediction: {map_label_to_string(nb_predictions[i])}\")\n",
        "    print(f\"Logistic Regression Prediction: {map_label_to_string(lr_predictions[i])}\")\n",
        "    print(f\"SVM Prediction: {map_label_to_string(svm_predictions[i])}\")\n",
        "    print(f\"Ensemble Prediction: {map_label_to_string(ensemble_predictions[i])}\")\n",
        "    print(\"-\" * 60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN-6c1Cj-zfl",
        "outputId": "c9c358e2-04bd-44ec-935d-6dcefbeafd48"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "     v1                                                 v2 Unnamed: 2  \\\n",
            "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
            "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
            "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
            "\n",
            "  Unnamed: 3 Unnamed: 4  \n",
            "0        NaN        NaN  \n",
            "1        NaN        NaN  \n",
            "2        NaN        NaN  \n",
            "3        NaN        NaN  \n",
            "4        NaN        NaN  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   v1          5572 non-null   object\n",
            " 1   v2          5572 non-null   object\n",
            " 2   Unnamed: 2  50 non-null     object\n",
            " 3   Unnamed: 3  12 non-null     object\n",
            " 4   Unnamed: 4  6 non-null      object\n",
            "dtypes: object(5)\n",
            "memory usage: 217.8+ KB\n",
            "None\n",
            "label      0\n",
            "message    0\n",
            "dtype: int64\n",
            "Naive Bayes - Accuracy: 0.9668161434977578, Precision: 1.0, Recall: 0.7533333333333333, F1-Score: 0.8593155893536121\n",
            "Logistic Regression - Accuracy: 0.9524663677130045, Precision: 0.970873786407767, Recall: 0.6666666666666666, F1-Score: 0.7905138339920948\n",
            "SVM - Accuracy: 0.979372197309417, Precision: 0.9703703703703703, Recall: 0.8733333333333333, F1-Score: 0.9192982456140351\n",
            "Best parameters for Logistic Regression: {'C': 100, 'solver': 'liblinear'}\n",
            "Ensemble - Accuracy: 0.9811659192825112, Precision: 0.9708029197080292, Recall: 0.8866666666666667, F1-Score: 0.926829268292683\n",
            "Example Messages Classification:\n",
            "\n",
            "Message: Congratulations! You've won a $1,000 Walmart gift card. Go to http://bit.ly/12345 to claim now.\n",
            "Naive Bayes Prediction: spam\n",
            "Logistic Regression Prediction: spam\n",
            "SVM Prediction: spam\n",
            "Ensemble Prediction: spam\n",
            "------------------------------------------------------------\n",
            "Message: Hey, are we still meeting for lunch tomorrow?\n",
            "Naive Bayes Prediction: ham\n",
            "Logistic Regression Prediction: ham\n",
            "SVM Prediction: ham\n",
            "Ensemble Prediction: ham\n",
            "------------------------------------------------------------\n",
            "Message: URGENT! Your account has been compromised. Click the link to secure it.\n",
            "Naive Bayes Prediction: ham\n",
            "Logistic Regression Prediction: ham\n",
            "SVM Prediction: spam\n",
            "Ensemble Prediction: spam\n",
            "------------------------------------------------------------\n",
            "Message: Don't forget to bring your assignment to class.\n",
            "Naive Bayes Prediction: ham\n",
            "Logistic Regression Prediction: ham\n",
            "SVM Prediction: ham\n",
            "Ensemble Prediction: ham\n",
            "------------------------------------------------------------\n",
            "Message: Get 50% off your next purchase at our store. Limited time offer.\n",
            "Naive Bayes Prediction: ham\n",
            "Logistic Regression Prediction: ham\n",
            "SVM Prediction: spam\n",
            "Ensemble Prediction: spam\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for data balancing and feature engineering\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Function to evaluate models\n",
        "def evaluate_model(predictions, y_test):\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    precision = precision_score(y_test, predictions)\n",
        "    recall = recall_score(y_test, predictions)\n",
        "    f1 = f1_score(y_test, predictions)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to the dataset in Google Drive\n",
        "data_path = '/content/drive/My Drive/spam.csv'\n",
        "\n",
        "# Load the dataset with a different encoding to handle potential encoding issues\n",
        "data = pd.read_csv(data_path, encoding='latin1')\n",
        "\n",
        "# Drop unnecessary columns and rename columns for convenience\n",
        "data = data[['v1', 'v2']]\n",
        "data.columns = ['label', 'message']\n",
        "\n",
        "# Map labels to binary values (ham: 0, spam: 1)\n",
        "data['label'] = data['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Check for any missing values\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['message'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to extract meta-features\n",
        "def extract_meta_features(text_series):\n",
        "    return pd.DataFrame({\n",
        "        'message_length': text_series.apply(len),\n",
        "        'num_special_chars': text_series.apply(lambda x: sum(not c.isalnum() for c in x)),\n",
        "        'num_urls': text_series.apply(lambda x: x.count('http'))\n",
        "    })\n",
        "\n",
        "# Combine text and meta-features\n",
        "combined_features = ColumnTransformer([\n",
        "    ('tfidf', TfidfVectorizer(stop_words='english', max_df=0.7, ngram_range=(1, 2)), 'message'),\n",
        "    ('meta', FunctionTransformer(extract_meta_features, validate=False), 'message')\n",
        "])\n",
        "\n",
        "# Transform training and test data\n",
        "X_train_transformed = combined_features.fit_transform(pd.DataFrame(X_train, columns=['message']))\n",
        "X_test_transformed = combined_features.transform(pd.DataFrame(X_test, columns=['message']))\n",
        "\n",
        "# Apply SMOTE to balance the dataset\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_transformed, y_train)\n",
        "\n",
        "# Train Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train_balanced, y_train_balanced)\n",
        "nb_predictions = nb_classifier.predict(X_test_transformed)\n",
        "nb_results = evaluate_model(nb_predictions, y_test)\n",
        "print(f'Naive Bayes - Accuracy: {nb_results[0]}, Precision: {nb_results[1]}, Recall: {nb_results[2]}, F1-Score: {nb_results[3]}')\n",
        "\n",
        "# Train Logistic Regression classifier\n",
        "lr_classifier = LogisticRegression(max_iter=1000)\n",
        "lr_classifier.fit(X_train_balanced, y_train_balanced)\n",
        "lr_predictions = lr_classifier.predict(X_test_transformed)\n",
        "lr_results = evaluate_model(lr_predictions, y_test)\n",
        "print(f'Logistic Regression - Accuracy: {lr_results[0]}, Precision: {lr_results[1]}, Recall: {lr_results[2]}, F1-Score: {lr_results[3]}')\n",
        "\n",
        "# Train SVM classifier\n",
        "svm_classifier = SVC(probability=True)\n",
        "svm_classifier.fit(X_train_balanced, y_train_balanced)\n",
        "svm_predictions = svm_classifier.predict(X_test_transformed)\n",
        "svm_results = evaluate_model(svm_predictions, y_test)\n",
        "print(f'SVM - Accuracy: {svm_results[0]}, Precision: {svm_results[1]}, Recall: {svm_results[2]}, F1-Score: {svm_results[3]}')\n",
        "\n",
        "# Define and train ensemble classifier\n",
        "voting_clf = VotingClassifier(estimators=[\n",
        "    ('nb', nb_classifier),\n",
        "    ('lr', lr_classifier),\n",
        "    ('svm', svm_classifier)\n",
        "], voting='soft')\n",
        "\n",
        "voting_clf.fit(X_train_balanced, y_train_balanced)\n",
        "ensemble_predictions = voting_clf.predict(X_test_transformed)\n",
        "ensemble_results = evaluate_model(ensemble_predictions, y_test)\n",
        "print(f'Ensemble - Accuracy: {ensemble_results[0]}, Precision: {ensemble_results[1]}, Recall: {ensemble_results[2]}, F1-Score: {ensemble_results[3]}')\n",
        "\n",
        "# Create example messages for prediction\n",
        "example_messages = [\n",
        "    \"Congratulations! You've won a $1,000 Walmart gift card. Go to http://bit.ly/12345 to claim now.\",\n",
        "    \"Hey, are we still meeting for lunch tomorrow?\",\n",
        "    \"URGENT! Your account has been compromised. Click the link to secure it.\",\n",
        "    \"Don't forget to bring your assignment to class.\",\n",
        "    \"Get 50% off your next purchase at our store. Limited time offer.\"\n",
        "]\n",
        "\n",
        "# Transform example messages using the same feature extractor\n",
        "example_messages_transformed = combined_features.transform(pd.DataFrame(example_messages, columns=['message']))\n",
        "\n",
        "# Make predictions using the ensemble classifier\n",
        "example_predictions = voting_clf.predict(example_messages_transformed)\n",
        "\n",
        "# Define a function to map the label to a string for readability\n",
        "def map_label_to_string(label):\n",
        "    return 'spam' if label == 1 else 'ham'\n",
        "\n",
        "# Display the results for the example messages\n",
        "print(\"Example Messages Classification:\\n\")\n",
        "for i, message in enumerate(example_messages):\n",
        "    print(f\"Message: {message}\")\n",
        "    print(f\"Ensemble Prediction: {map_label_to_string(example_predictions[i])}\")\n",
        "    print(\"-\" * 60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqANCc96_YwA",
        "outputId": "f9732b0b-16f1-4566-b6d8-6cc29e5fdb52"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "label      0\n",
            "message    0\n",
            "dtype: int64\n",
            "Naive Bayes - Accuracy: 0.579372197309417, Precision: 0.24232633279483037, Recall: 1.0, F1-Score: 0.39011703511053314\n",
            "Logistic Regression - Accuracy: 0.9524663677130045, Precision: 0.7740112994350282, Recall: 0.9133333333333333, F1-Score: 0.8379204892966361\n",
            "SVM - Accuracy: 0.8322869955156951, Precision: 0.4401294498381877, Recall: 0.9066666666666666, F1-Score: 0.5925925925925926\n",
            "Ensemble - Accuracy: 0.8358744394618834, Precision: 0.4482758620689655, Recall: 0.9533333333333334, F1-Score: 0.6098081023454157\n",
            "Example Messages Classification:\n",
            "\n",
            "Message: Congratulations! You've won a $1,000 Walmart gift card. Go to http://bit.ly/12345 to claim now.\n",
            "Ensemble Prediction: spam\n",
            "------------------------------------------------------------\n",
            "Message: Hey, are we still meeting for lunch tomorrow?\n",
            "Ensemble Prediction: ham\n",
            "------------------------------------------------------------\n",
            "Message: URGENT! Your account has been compromised. Click the link to secure it.\n",
            "Ensemble Prediction: spam\n",
            "------------------------------------------------------------\n",
            "Message: Don't forget to bring your assignment to class.\n",
            "Ensemble Prediction: ham\n",
            "------------------------------------------------------------\n",
            "Message: Get 50% off your next purchase at our store. Limited time offer.\n",
            "Ensemble Prediction: ham\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}